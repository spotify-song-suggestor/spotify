{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd035c03aa0d851cb6285394a035bf26f38eed74d8588e29c3dd9d14089f75b8b7c",
   "display_name": "Python 3.8.8 64-bit ('NLP-MTXprD7X': pipenv)"
  },
  "metadata": {
   "interpreter": {
    "hash": "1eb1274d9b46011db3fd7736afbfd78351ce92e021db6530fd6b2630829fc1c2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as skl\n",
    "from tensorflow import keras\n",
    "from sklearn.neighbors import kneighbors_graph, NearestNeighbors\n",
    "from tensorflow.keras.layers import Dense, LeakyReLU\n",
    "from tensorflow.keras.optimizers import Adam, Nadam, RMSprop, SGD\n",
    "from tensorflow.keras.utils import plot_model, to_categorical\n",
    "from tensorflow.keras.models import Model, Sequential, save_model, load_model\n",
    "from tensorflow.config import list_logical_devices\n",
    "from tensorflow.keras.callbacks import TensorBoard"
   ]
  },
  {
   "source": [
    "### Data Preparation\n",
    "\n",
    "#### We removed null values, entries with duplicate song name / artists pairs, and normalized the numerical features for use in a neural network.\n",
    "#### We also case-normalized the text in the data to make things a bit easier on the queries.\n",
    "\n",
    "### Model Architecture\n",
    "\n",
    "#### I tried 4 different models built with 2 different major architectures. Both architectures are autoencoders, but have some slight differences.\n",
    "\n",
    "#### The first model architecture is deeper and wider than the second, with a larger latent vector. After I tried a few different optimizers and loss functions,\n",
    "\n",
    "#### I settled on mean absolute error for the loss function for each model as it gave the best looking results.\n",
    "\n",
    "#### The second model architecture uses LeakyReLU activation functions, is smaller, and has a smaller latent vector. The second model made from this architecture, dubbed\n",
    "#### a very plain name of ae4 (autoencoder 4) utilizes RMSProp as the optimizer, and each LeakyReLU has an alpha of 0.3.\n",
    "\n",
    "#### After looking at the output for each model with various songs, it seemed that ae4 had the most consistently understandable recommendations, so I saved that model, its encoded vectors for the entire dataset, and the K-NearestNeighbors model used to relate the encoded vectors for recommendation. These are what is used in the application."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_full.to_csv('model_ready_data_no_dupes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Completely cleaned data\n",
    "df_full = pd.read_csv(r'C:\\Users\\Logan\\Desktop\\model_ready_data_no_dupes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save numerical features for model in separate dataframe\n",
    "df = df_full.select_dtypes('number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numpy array\n",
    "data = df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(524211, 15)"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['duration_ms', 'explicit', 'danceability', 'energy', 'key', 'loudness',\n",
       "       'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness',\n",
       "       'valence', 'tempo', 'time_signature', 'popularity'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['name', 'duration_ms', 'explicit', 'artists', 'release_date',\n",
       "       'danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness',\n",
       "       'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo',\n",
       "       'time_signature', 'popularity'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "df_full.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow subclass API\n",
    "\n",
    "class AutoEncoder(Model):\n",
    "    def __init__(self):\n",
    "        #Inherit init from Model base class\n",
    "        super(AutoEncoder, self).__init__()\n",
    "\n",
    "        # Encoder portion utilizing Keras Sequential\n",
    "        self.encoder = Sequential([\n",
    "            Dense(64, input_shape=(data.shape[1],), activation='relu'),\n",
    "            Dense(32, activation='relu'),\n",
    "            Dense(16, activation='relu'),\n",
    "            Dense(8, activation='gelu')])\n",
    "        # Encoder portion utilizing Keras Sequential\n",
    "        self.decoder = Sequential([\n",
    "            Dense(16, activation='gelu'),\n",
    "            Dense(32, activation='relu'),\n",
    "            Dense(64, activation='relu'),\n",
    "            Dense(15, activation='relu')])\n",
    "\n",
    "    # This function is used by fit to pass data through both the encoder and decoder\n",
    "    def call(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae = AutoEncoder()\n",
    "ae.compile(optimizer='adam', loss='mae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae.fit(data, data, shuffle=True, epochs=10, workers=10, use_multiprocessing=True, validation_split=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_data = ae.encoder(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = NearestNeighbors(n_neighbors=5, radius=1, n_jobs=-1)\n",
    "knn.fit(encoded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = AutoEncoder()\n",
    "loss = tf.keras.losses.MeanAbsoluteError()\n",
    "model_2.compile(optimizer='nadam', loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.fit(data, data, epochs=10, shuffle=True, validation_split=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_data_2 = model_2.encoder(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_2 = NearestNeighbors(n_neighbors=5, n_jobs=-1)\n",
    "knn_2.fit(encoded_data_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as above, just a different architecture\n",
    "class AutoEncoder2(Model):\n",
    "    def __init__(self, alpha):\n",
    "        super(AutoEncoder2, self).__init__()\n",
    "\n",
    "        self.encoder = Sequential([\n",
    "            Dense(32, input_shape=data.shape[1:]),\n",
    "            LeakyReLU(alpha),\n",
    "            Dense(16),\n",
    "            LeakyReLU(alpha),\n",
    "            Dense(5),\n",
    "            LeakyReLU(alpha)])\n",
    "\n",
    "        self.decoder = Sequential([\n",
    "            Dense(16),\n",
    "            LeakyReLU(alpha),\n",
    "            Dense(32),\n",
    "            LeakyReLU(alpha),\n",
    "            Dense(15),\n",
    "            LeakyReLU(alpha)])\n",
    "    \n",
    "\n",
    "    def call(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae2 = AutoEncoder2(.1)\n",
    "ae2.compile(optimizer='adam', loss='mae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae2.fit(data, data, epochs=10, validation_split=.1, workers=10, use_multiprocessing=True, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_data_3 = ae2.encoder(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_3 = NearestNeighbors(n_neighbors=5, n_jobs=-1)\n",
    "knn_3.fit(encoded_data_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae4 = AutoEncoder2(.3)\n",
    "ae4.compile(optimizer='rmsprop', loss='mae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae4.fit(data, data, epochs=10, validation_split=.1, workers=10, use_multiprocessing=True, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ae4.save('ae4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae4 = load_model('assets/ae4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "NearestNeighbors(n_jobs=-1)"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "encoded_data_4 = ae4.encoder(data)\n",
    "knn4 = NearestNeighbors(n_jobs=-1)\n",
    "knn4.fit(encoded_data_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joblib.dump(encoded_data_4, 'encoded_data.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 72837\n",
    "\n",
    "# _, ind = knn.kneighbors([encoded_data[query]])\n",
    "# _, ind2 = knn_2.kneighbors([encoded_data_2[query]])\n",
    "# _, ind3 = knn_3.kneighbors([encoded_data_3[query]])\n",
    "_, ind4 = knn4.kneighbors([encoded_data_4[query]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.iloc[ind[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.iloc[ind2[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.iloc[ind3[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                     name  duration_ms  explicit                    artists  \\\n",
       "72837             duality     0.044939         0             [\"'slipknot'\"]   \n",
       "71911    bring me to life     0.041965         0          [\"'evanescence'\"]   \n",
       "77786             eyeless     0.042048         1             [\"'slipknot'\"]   \n",
       "50622       ace of spades     0.029695         0            [\"'motörhead'\"]   \n",
       "73246  give 'em hell, kid     0.024699         0  [\"'my chemical romance'\"]   \n",
       "\n",
       "      release_date  danceability  energy       key  loudness  mode  \\\n",
       "72837         2004         0.354   0.982  0.363636  0.871482     0   \n",
       "71911   2003-03-04         0.331   0.943  0.363636  0.869004     0   \n",
       "77786   2009-09-09         0.293   0.997  0.363636  0.851016     0   \n",
       "50622   1980-11-08         0.329   0.974  0.272727  0.783621     0   \n",
       "73246   2004-06-08         0.252   0.993  0.363636  0.870671     0   \n",
       "\n",
       "       speechiness  acousticness  instrumentalness  liveness  valence  \\\n",
       "72837       0.1680      0.000237          0.000294    0.2040    0.194   \n",
       "71911       0.0698      0.007210          0.000002    0.2420    0.296   \n",
       "77786       0.2170      0.000463          0.000039    0.4150    0.130   \n",
       "50622       0.1350      0.000852          0.000118    0.0904    0.234   \n",
       "73246       0.1600      0.023400          0.000000    0.2280    0.118   \n",
       "\n",
       "          tempo  time_signature  popularity  \n",
       "72837  0.583535             0.8        0.78  \n",
       "71911  0.384007             0.8        0.81  \n",
       "77786  0.407288             0.8        0.61  \n",
       "50622  0.571724             0.8        0.75  \n",
       "73246  0.745889             0.8        0.62  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>duration_ms</th>\n      <th>explicit</th>\n      <th>artists</th>\n      <th>release_date</th>\n      <th>danceability</th>\n      <th>energy</th>\n      <th>key</th>\n      <th>loudness</th>\n      <th>mode</th>\n      <th>speechiness</th>\n      <th>acousticness</th>\n      <th>instrumentalness</th>\n      <th>liveness</th>\n      <th>valence</th>\n      <th>tempo</th>\n      <th>time_signature</th>\n      <th>popularity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>72837</th>\n      <td>duality</td>\n      <td>0.044939</td>\n      <td>0</td>\n      <td>[\"'slipknot'\"]</td>\n      <td>2004</td>\n      <td>0.354</td>\n      <td>0.982</td>\n      <td>0.363636</td>\n      <td>0.871482</td>\n      <td>0</td>\n      <td>0.1680</td>\n      <td>0.000237</td>\n      <td>0.000294</td>\n      <td>0.2040</td>\n      <td>0.194</td>\n      <td>0.583535</td>\n      <td>0.8</td>\n      <td>0.78</td>\n    </tr>\n    <tr>\n      <th>71911</th>\n      <td>bring me to life</td>\n      <td>0.041965</td>\n      <td>0</td>\n      <td>[\"'evanescence'\"]</td>\n      <td>2003-03-04</td>\n      <td>0.331</td>\n      <td>0.943</td>\n      <td>0.363636</td>\n      <td>0.869004</td>\n      <td>0</td>\n      <td>0.0698</td>\n      <td>0.007210</td>\n      <td>0.000002</td>\n      <td>0.2420</td>\n      <td>0.296</td>\n      <td>0.384007</td>\n      <td>0.8</td>\n      <td>0.81</td>\n    </tr>\n    <tr>\n      <th>77786</th>\n      <td>eyeless</td>\n      <td>0.042048</td>\n      <td>1</td>\n      <td>[\"'slipknot'\"]</td>\n      <td>2009-09-09</td>\n      <td>0.293</td>\n      <td>0.997</td>\n      <td>0.363636</td>\n      <td>0.851016</td>\n      <td>0</td>\n      <td>0.2170</td>\n      <td>0.000463</td>\n      <td>0.000039</td>\n      <td>0.4150</td>\n      <td>0.130</td>\n      <td>0.407288</td>\n      <td>0.8</td>\n      <td>0.61</td>\n    </tr>\n    <tr>\n      <th>50622</th>\n      <td>ace of spades</td>\n      <td>0.029695</td>\n      <td>0</td>\n      <td>[\"'motörhead'\"]</td>\n      <td>1980-11-08</td>\n      <td>0.329</td>\n      <td>0.974</td>\n      <td>0.272727</td>\n      <td>0.783621</td>\n      <td>0</td>\n      <td>0.1350</td>\n      <td>0.000852</td>\n      <td>0.000118</td>\n      <td>0.0904</td>\n      <td>0.234</td>\n      <td>0.571724</td>\n      <td>0.8</td>\n      <td>0.75</td>\n    </tr>\n    <tr>\n      <th>73246</th>\n      <td>give 'em hell, kid</td>\n      <td>0.024699</td>\n      <td>0</td>\n      <td>[\"'my chemical romance'\"]</td>\n      <td>2004-06-08</td>\n      <td>0.252</td>\n      <td>0.993</td>\n      <td>0.363636</td>\n      <td>0.870671</td>\n      <td>0</td>\n      <td>0.1600</td>\n      <td>0.023400</td>\n      <td>0.000000</td>\n      <td>0.2280</td>\n      <td>0.118</td>\n      <td>0.745889</td>\n      <td>0.8</td>\n      <td>0.62</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "df_full.iloc[ind4[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full[df_full['artists'].str.contains('slipkn') == True].head(50)"
   ]
  }
 ]
}